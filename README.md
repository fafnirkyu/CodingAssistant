# Qwen v3 30B â€” Local Personal Coding Assistant

A fully local, project-aware coding companion powered by [Qwen v3 30B](https://huggingface.co/Qwen) running via [Ollama](https://ollama.com/).  
This assistant helps you write, debug, and manage code across multiple projects with file context awareness, streaming responses, and automatic file saving.

---

## âœ¨ Features

- **Local LLM** â€” Uses Qwen v3 30B for high-quality coding assistance, no cloud API required.
- **Project-based Context** â€” Automatically reads your project's files to provide relevant context in responses.
- **Multi-file Editing** â€” Generates and saves multiple files directly to your project folder.
- **Streaming Output** â€” Real-time, token-by-token response streaming.
- **Web Search** â€” Integrated DuckDuckGo API for quick information lookup.
- **File Uploads** â€” Upload project files directly via the web UI.
- **Persistent Chat Memory** â€” Remembers previous interactions per project using SQLite.
- **Dark Mode UI** â€” Clean, responsive interface with Markdown and syntax highlighting.

---

## ğŸ“‚ Project Structure

.
â”œâ”€â”€ backend/
â”‚ â””â”€â”€ app.py # Flask backend with Ollama integration
â”œâ”€â”€ static/
â”‚ â”œâ”€â”€ styles.css # Dark mode styling
â”‚ â””â”€â”€ script.js # Frontend interactivity & streaming
â”œâ”€â”€ templates/
â”‚ â””â”€â”€ index.html # Web interface
â”œâ”€â”€ projects/ # Your saved coding projects
â”œâ”€â”€ memory.db # SQLite chat history database
â””â”€â”€ README.md

---

## ğŸ› ï¸ Requirements

- Python 3.9+
- [Ollama](https://ollama.com/) installed and running locally
- Qwen v3 30B model pulled via Ollama:
  
  ollama pull qwen3-coder:30b
  
Node & npm (optional, if you plan to extend the frontend)

Python dependencies:

pip install flask requests ollama

ğŸš€ Usage
Start Ollama:

ollama serve

Run the Backend:

python backend/app.py
Open the Web UI:
Go to http://localhost:5000 in your browser.

Create a Project:
Click Add Project, then start chatting. The assistant will:

Read small project files for context

Provide explanations & runnable code

Save generated files directly into your project folder

ğŸ’¡ Tips

Use requirements.txt or README.md in your project â€” the assistant prioritizes them for context.

Press Ctrl+Enter to send messages quickly.

Uploaded files are automatically added to the active project's context.

ğŸ§© Technology Stack

Backend

Python 3.9+ â€” Core backend language.

Flask â€” Lightweight web framework for handling API routes and serving the web UI.

SQLite â€” Embedded database for persistent per-project chat history.

Ollama â€” Local LLM runner for Qwen v3 30B.

Qwen v3 30B â€” Large Language Model specialized for coding and reasoning.

Requests â€” HTTP client for DuckDuckGo search API.

Frontend

HTML5 â€” Web interface structure.

CSS3 â€” Custom dark mode styling.

JavaScript (ES6+) â€” Client-side logic for chat interaction & streaming.

Fetch API â€” Asynchronous communication with the backend.

Marked.js â€” Client-side Markdown rendering for assistant messages.

Highlight.js â€” Syntax highlighting for code blocks.

ğŸ”’ Privacy

Everything runs entirely locally.
No data is sent to external services except optional DuckDuckGo search queries.

